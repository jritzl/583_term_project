This is a README file for implementing the project code. The project consists of three parts: ultrasound classification, MNIST and CIFAR classification, and MATLAB code.

The MATLAB implementation includes a single matlab.m file that works with the digitdataset and CIFAR-10 datasets. For the digit dataset, the implementation uses fitcecoc up to line 52. Inputs are sourced from MATLAB toolboxes, divided into training and testing datasets. The model is then trained, tested using the predict function, and the accuracy is calculated. Finally, a confusion matrix is generated.

For CIFAR-10, the process is similar, but loading the data requires additional steps. You need to download the CIFAR-10 dataset for MATLAB from its website. Once the data is loaded, the implementation follows the same steps as for the digit dataset.





For the MNIST and CIFAR classification, there are seven files. 

The `utils2.py` file is used for generating random labels and images during training. It has minimal parameters and is called from `train2.py`. 

In `models2.py`, the generator and discriminator are defined. These models work with 28x28 images. To adapt the implementation for CIFAR-10, the last two `ConvTranspose2d` layers in the generator need their kernel sizes increased to 4, and the output channels should be set to 3 for RGB images. Similarly, the input channels for the discriminator should be updated to 3, and the first two `Conv2d` layers should have kernel sizes of 4.

For training, the model and utilities are called, and the dataset is loaded using `datasets` from `torchvision`. The optimizer is configured, and the loss functions are arranged. The training code is straightforward and performs as expected.

After training, you can use `generator.py` to create fake images generated by the trained model, with labels corresponding to the images.

In `test2.py`, accuracies and confusion matrices are calculated to evaluate the model. 

The `cnn.py` file is used for training a CNN without a GAN. The same classifier from `models2.py` is used, but only the classifier loss is backpropagated, unlike in the GAN case. 

`cnntest.py` is a version of `test2.py` adapted for evaluating the CNN training. 


Lastly, we have the ultrasound case.

The ultrasound images were initially too large and challenging to train, so I resized them to 32x32. This allowed the same model used for CIFAR-10 to be applied. All files are the same as in the MNIST and CIFAR-10 classification, with only one main difference.

The dataset is loaded using a class called UltrasoundDataset. This class takes the images and labels, maps the labels to integers, and returns the images and labels while considering the channel, height, and width dimensions. The images and labels are extracted from a zip file, and the UltrasoundDataset class is used to load the data. The rest of the process is the same as for the MNIST case.




